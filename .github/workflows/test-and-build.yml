name: Python application test with pytest
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  AIRFLOW_HOME: /home/runner/work/bi-dags/bi-dags
  REGISTRY: registry.cern.ch
  IMAGE: cern-sis/bi-dags

jobs:
  build_test:
    name: Build and Test
    runs-on: ubuntu-latest
    services:
      redis:
        image: redis
        ports:
          - 6379:6379
      postgres:
        image: postgres:13
        env:
          POSTGRES_USER: airflow
          POSTGRES_PASSWORD: airflow
          POSTGRES_DB: airflow
        ports:
          - 5432:5432
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Install Python 3
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      - name: Build Image
        id: build
        uses: cern-sis/gh-workflows/.github/actions/docker-build@v6.5
        with:
          registry: ${{ env.REGISTRY }}
          image: ${{ env.IMAGE }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
          cache: false
          username: ${{ secrets.HARBOR_USERNAME }}
          password: ${{ secrets.HARBOR_PASSWORD }}

      - name: Run tests with pytest and generate report
        run: >
          docker run
          --name biproject
          --network=host
          -v "$(pwd)"/tests:/opt/airflow/tests
          -v "$(pwd)"/scripts:/opt/airflow/scripts
          -e AIRFLOW__CORE__EXECUTOR=CeleryExecutor
          -e AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@127.0.0.1:5432/airflow
          -e AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow@127.0.0.1:5432/airflow
          -e AIRFLOW__CELERY__BROKER_URL=redis://:@127.0.0.1:6379/0
          -e AIRFLOW__CORE__FERNET_KEY=""
          -e AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION="true"
          -e AIRFLOW__CORE__LOAD_EXAMPLES="false"
          $REGISTRY/$IMAGE@${{ steps.build.outputs.image-digest }}
          bash -c "airflow db migrate && airflow connections import /opt/airflow/scripts/connections/connections.json && pytest /opt/airflow/tests --cov --cov-report=xml"

      - name: Copy test coverage file to host machine
        run: docker cp biproject:/opt/airflow/coverage.xml .

      - name: Upload Coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          verbose: true

      - name: Deploy QA
        if: ${{ github.event_name == 'push' }}
        uses: cern-sis/gh-workflows/.github/actions/kubernetes-project-new-images@v6.3.1
        with:
          repo: cern-sis/kubernetes-airflow
          event-type: update
          images: ${{ fromJSON(steps.build.outputs.json).tags[1] }}
          token: ${{ secrets.CERN_SIS_BOT }}
